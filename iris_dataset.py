# -*- coding: utf-8 -*-
"""iris_dataset

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t0PgKIwmPTz6A1PMh-CztLP3NWwAzJns
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv('/IRIS.csv')
df

df.head(1)

df.head()

# to display stats about data
df.describe()

#to display basic info
df.info()

# to display no of samples on each class
df['species'].value_counts()

df['species'].isnull().sum()

df.columns

df.shape

"""**Preprocessing Dataset**"""

# preprocessing is used for searching of  null values present or not in a dataset

"""Exploratory dataset"""

# in exploratory dataset we plot the coluumns using hist or other ,with helps us to learn things easily.

"""**Example**"""

df.hist(figsize=(10,10))
plt.show()

#we can also plot as
df['sepal_length'].hist()
plt.show()

"""**scatter_plot**"""

colors=['red','green','blue']
species=list(set(df['species']))
for i in range(3):
    x=df[df['species']==species[i]]
    plt.scatter(x['sepal_length'],x['sepal_width'],c=colors[i],label=species[i])
    plt.xlabel('sepal_length')
    plt.ylabel('sepal_width')
    plt.legend()
    plt.show()

df['species'].value_counts()

colors=['red','green','blue']
species=list(set(df['species']))
for i in range(3):
    x=df[df['species']==species[i]]
    plt.scatter(x['petal_length'],x['petal_width'],c=colors[i],label=species[i])
    plt.xlabel('petal_length')
    plt.ylabel('petal_width')
    plt.legend()
    plt.show()

"""# we can also get the above plots as

"""

colors=['red','yellow','blue']
species=['Iris-setosa','Iris-versicolor','Iris-virginica']
for i in range(3):
  x=df[df['species']==species[i]]
  plt.scatter(x['sepal_length'],x['sepal_width'],c=colors[i],label=species[i])
  plt.xlabel('sepal_length')
  plt.ylabel('sepal_width')
  plt.legend()
  plt.show()

"""**coorelation_Matrix**
# A correlation matrix is a table showing correlation coefficients between variables.Each cell inthe table shown the correlation between two variables.The values is in the range of -1 to 1.if two variables have high correlation ,we can neglect one variable form those two.
"""

# if we directly code as df.corr() we get an error.
# for that we can code as
numeric_df=df.select_dtypes(include=['number'])
correlation_matrix=numeric_df.corr()
print(correlation_matrix)

corr=correlation_matrix
plt.subplots(figsize=(3,4))
sns.heatmap(corr,annot=True)
plt.show()

"""**Label_encoders**

Machine learning encoders refers in datasets there are many column containing labels with words or number.but to make the machine to understand this we need to change it to machine understandable format for that we label encoders.
"""

from  sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df['species']=le.fit_transform(df['species'])
df.head(3)

from sklearn.model_selection import train_test_split
x=df.drop(columns='species')
y=df['species']
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)
from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()
lr.fit(x_train,y_train)

"""**accuraccy_checking**"""

# we cannot use direct x_test in accuracy_score finding
# to get the accuracy of the test data need to convert it first into predict .
from sklearn.metrics import accuracy_score
y_pred=lr.predict(x_test)
accuracy_score(y_pred,y_test)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix,classification_report
knn=KNeighborsClassifier()
knn.fit(x_train,y_train)
y_pred=knn.predict(x_test)
print('accuracy_score',accuracy_score(y_pred,y_test))
#A confusion matrix is used to measure the performance of a classifier in depth.
#In this simple guide to Confusion Matrix, we will get to understand and learn confusion matrices better.
print('confusion_matrix',confusion_matrix(y_pred,y_test))
#The classification report shows a representation of the main classification metrics on a per-class basis.
#This gives a deeper intuition of the classifier behavior over global accuracy which can mask functional weaknesses in one class of a multiclass problem.
print(classification_report(y_pred,y_test))

from sklearn.tree import DecisionTreeClassifier
dt=DecisionTreeClassifier
dt.fit(x_train,y_train)
y_pred=dt.predict(x_test)
from sklearn.metrics import accuracy_score
print('accuracy_score',accuracy_score(y_pred,y_test))